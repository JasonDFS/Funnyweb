00:0.64 We've optimized our computer analytics where to next?
00:3.55 Well let's look at this search.
00:4.73 It's Not very fast. It did take 1.4 seconds.
00:9.44 You know, I think the internet is just being slow right now.
00:12.86 Let's try to run it again and see if what the time is going to be
00:16.31 like. If we look into it over here,
00:19.62 you'll notice there's not a lot we can do we call get on requests and then
00:24.84 you know, that's that's it.
00:26.18 We wait let's just go see if there's any sort of difference over here now.
00:31.66 It's 448 milliseconds. That's a huge difference.
00:34.46 But what are we gonna do?
00:35.84 There's not a whole lot else we can do.
00:38.44 I'll go and keep this as our baseline now.
00:40.94 But we've got search not a lot we can do compute analytics which we've made about
00:45.01 10 times faster. And now we've got get records And over here and get records
00:49.21 We have create connection being called once that's 12% and there's run query which is
00:55.87 really running read row. So Send query might be the place to focus on but
01:0.79 notice 889888. So read row is actually really the challenge.
01:6.04 Let's go and focus on this section.
01:10.04 They're down here. Again, we're simulating.
01:12.38 We're not creating a real database with huge amounts of data that will make a slow
01:16.09 query. But imagine we're doing a query against a database here and then because it
01:21.23 has a lot of data, it's somewhat slow when we're working with databases and we
01:25.89 have a lot of data. The thing you can do more than almost any other
01:30.11 thing to make it faster is to add an index.
01:33.28 So let's imagine there was and this one we had no index and we decided,
01:38.54 you know what, we're going to go and look at the query performance stuff over
01:43.48 in the database and realize, oh,
01:44.82 there's no data, there's no index on this.
01:47.24 That's a problem adding an index when there's tons of data can easily make a query
01:52.62 1000 times faster. Let's just imagine this one makes it 100 times faster.
01:57.44 So put a couple zeros there again,
02:0.53 somewhat contrived. But this is real world type of stuff.
02:3.96 You see a database query that's slow and you go and you optimize it by optimize
02:9.16 it in the database first. The other thing that's often done in this case is
02:13.43 if you want to run a query we might use something like Redis or an in
02:17.2 memory cache where we cash the results.
02:19.38 So we don't even go to the database again.
02:21.65 But in my mind it's better to make the database faster if that's at all possible
02:26.8 because adding a caching layer, all of a sudden you end up with cache invalidation
02:31.71 and staleness and all kinds of challenges.
02:33.77 So start by making the database faster.
02:36.13 That's what we're simulating by adding index that's running again,
02:40.34 we did it. Oh look at that.
02:41.74 This thing is starting to the zip.
02:43.54 So we can't really speed up the queries or the web request.
02:46.86 I'll make a quick comment before we wrap up this video on what we could do
02:51.16 some of the time. But in this situation we can't make it any faster.
02:54.74 The database seemed faster. And we already saw that this is much faster.
02:57.52 Let's profile it and get a real answer up over the call,
03:1.39 graph those side by side. See how we're doing.
03:5.68 Our program is still red because well,
03:7.98 that's the slowest thing here. It's always going to be true.
03:10.65 But look at how much faster we got on our get records Now,
03:14.51 it's 20% of the time, whereas before it was 55% goes from 1.1 second down
03:22.75 to just 0.26 or 265 milliseconds.
03:27.39 That is a huge improvement. All right,
03:30.43 well, I feel like we've massively optimized this app.
03:35.0 We've gone what was the very original one?
03:37.44 It was something like six seconds.
03:39.31 We've gone from six seconds. Stand at 1.2 and we've done that.
03:42.93 Being guided by what we got in this picture right here.
03:47.44 Make a small change. Run it in the profiler.
03:50.0 See if it got better if it got worse.
03:51.53 Don't don't keep it roll that back.
03:53.74 Make another change. Figure out what's slow now in this new context.
03:57.81 Optimize that and keep going and keep going.
04:0.44 My final comment on this search here.
04:2.45 What we're doing is we're going over and passing a search text profile.
04:7.65 profiling over to talk python and asking for the answer and it's got to go through
04:11.7 the internet all the ping Times and what not to the east coast from the west
04:15.27 coast of the U. S.
04:16.39 That is at least 100 milliseconds.
04:18.56 Ping time plus the server as to respond.
04:20.57 And we have to process and print out the results.
04:23.34 Okay, So we can't really do anything about that.
04:26.32 I mean we could not print out the results but we kind of want to see
04:29.41 them. We could not do the query but we need the answer.
04:32.21 Right? So on one hand it feels like,
04:34.65 well we can't do a whole lot but we could say if we're gonna if this
04:38.74 was more interactive, if it was longer running,
04:41.94 we could actually go up here and say at Funk tools and add an  
04:45.62 'lru_cache( )' to this as well.
04:47.54 At least that way, if we ever search for the same text twice it's going
04:51.9 to be twice as fast. The second time we ask for the search,
04:55.94 we're going to assume that the data set over there hasn't changed does sometimes,
05:0.25 but it's not that frequent when assuming hasn't changed for the lifetime of this app running
05:5.09 and we're just going to give back the same answer,
05:7.24 we can add this, it'll make zero difference in terms of performance because we're calling
05:10.94 it only once but if we were calling it multiple times with potentially the same input
05:14.66 we have a much better response there.
05:18.04 Alright, final time, let's go and run our app.
05:19.69 See how it works. Boom still works much,
05:22.79 much faster. Pretty awesome, right?
